{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ab528f-96c0-4fd8-a176-d2dea8a3b64c",
   "metadata": {},
   "source": [
    "## Model: MSCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf60911c-5740-4707-b1d8-248c0a3f86c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:30:35.660306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-10 21:30:36.649196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib\n",
      "2023-10-10 21:30:36.649327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib\n",
      "2023-10-10 21:30:36.649339: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from keras.utils import np_utils,plot_model\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from keras.layers import Dense, Dropout,Flatten,Conv1D,MaxPooling1D,AveragePooling1D\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7266eb7a-3615-46b6-8881-f29f4bb867a3",
   "metadata": {},
   "source": [
    "### input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738c77f9-8b58-4803-bb5d-282a213844cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 5.83 s, total: 2min 27s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_raw = pd.read_csv('../datasets/all_healthy_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc179b5f-1ec8-4d3d-923c-039f2555aaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11543, 25980)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829c3778-5522-45c7-b9b1-1a48be9cff79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cg00000292</th>\n",
       "      <th>cg00002426</th>\n",
       "      <th>cg00003994</th>\n",
       "      <th>cg00005847</th>\n",
       "      <th>cg00006414</th>\n",
       "      <th>cg00007981</th>\n",
       "      <th>cg00008493</th>\n",
       "      <th>cg00008713</th>\n",
       "      <th>cg00009407</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27653134</th>\n",
       "      <th>cg27654142</th>\n",
       "      <th>cg27655855</th>\n",
       "      <th>cg27655905</th>\n",
       "      <th>cg27657283</th>\n",
       "      <th>cg27661264</th>\n",
       "      <th>cg27662379</th>\n",
       "      <th>cg27662877</th>\n",
       "      <th>cg27665659</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM1500896</td>\n",
       "      <td>0.540079</td>\n",
       "      <td>0.564492</td>\n",
       "      <td>0.044907</td>\n",
       "      <td>0.699895</td>\n",
       "      <td>0.064083</td>\n",
       "      <td>0.042312</td>\n",
       "      <td>0.856228</td>\n",
       "      <td>0.072350</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710663</td>\n",
       "      <td>0.066649</td>\n",
       "      <td>0.837245</td>\n",
       "      <td>0.057018</td>\n",
       "      <td>0.049503</td>\n",
       "      <td>0.356949</td>\n",
       "      <td>0.069238</td>\n",
       "      <td>0.040596</td>\n",
       "      <td>0.126728</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM1500897</td>\n",
       "      <td>0.562377</td>\n",
       "      <td>0.563360</td>\n",
       "      <td>0.065536</td>\n",
       "      <td>0.639487</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>0.037802</td>\n",
       "      <td>0.828050</td>\n",
       "      <td>0.081527</td>\n",
       "      <td>0.056482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686128</td>\n",
       "      <td>0.070768</td>\n",
       "      <td>0.794794</td>\n",
       "      <td>0.057936</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.256544</td>\n",
       "      <td>0.064016</td>\n",
       "      <td>0.051418</td>\n",
       "      <td>0.122267</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM1500898</td>\n",
       "      <td>0.586262</td>\n",
       "      <td>0.556159</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.592859</td>\n",
       "      <td>0.072489</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.842531</td>\n",
       "      <td>0.075749</td>\n",
       "      <td>0.051566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719266</td>\n",
       "      <td>0.086908</td>\n",
       "      <td>0.827737</td>\n",
       "      <td>0.078091</td>\n",
       "      <td>0.053606</td>\n",
       "      <td>0.365556</td>\n",
       "      <td>0.054088</td>\n",
       "      <td>0.049267</td>\n",
       "      <td>0.155096</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM1500899</td>\n",
       "      <td>0.515197</td>\n",
       "      <td>0.582909</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.764413</td>\n",
       "      <td>0.057259</td>\n",
       "      <td>0.035079</td>\n",
       "      <td>0.867209</td>\n",
       "      <td>0.060494</td>\n",
       "      <td>0.050152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657433</td>\n",
       "      <td>0.078306</td>\n",
       "      <td>0.788525</td>\n",
       "      <td>0.052291</td>\n",
       "      <td>0.053358</td>\n",
       "      <td>0.269563</td>\n",
       "      <td>0.064488</td>\n",
       "      <td>0.047505</td>\n",
       "      <td>0.138939</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM1500900</td>\n",
       "      <td>0.617524</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.048714</td>\n",
       "      <td>0.436787</td>\n",
       "      <td>0.086947</td>\n",
       "      <td>0.038958</td>\n",
       "      <td>0.858944</td>\n",
       "      <td>0.079839</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698988</td>\n",
       "      <td>0.084030</td>\n",
       "      <td>0.799059</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.036543</td>\n",
       "      <td>0.277516</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.054901</td>\n",
       "      <td>0.115813</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11538</th>\n",
       "      <td>GSM1400057</td>\n",
       "      <td>0.813192</td>\n",
       "      <td>0.851833</td>\n",
       "      <td>0.063641</td>\n",
       "      <td>0.133013</td>\n",
       "      <td>0.083006</td>\n",
       "      <td>0.044553</td>\n",
       "      <td>0.954777</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773726</td>\n",
       "      <td>0.096861</td>\n",
       "      <td>0.773328</td>\n",
       "      <td>0.057141</td>\n",
       "      <td>0.051934</td>\n",
       "      <td>0.231402</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>0.040151</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>49.078713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11539</th>\n",
       "      <td>GSM1400058</td>\n",
       "      <td>0.786084</td>\n",
       "      <td>0.817049</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.076139</td>\n",
       "      <td>0.037249</td>\n",
       "      <td>0.964076</td>\n",
       "      <td>0.036162</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774994</td>\n",
       "      <td>0.121388</td>\n",
       "      <td>0.776687</td>\n",
       "      <td>0.053314</td>\n",
       "      <td>0.068269</td>\n",
       "      <td>0.299261</td>\n",
       "      <td>0.022777</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.036373</td>\n",
       "      <td>49.078713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11540</th>\n",
       "      <td>GSM1400059</td>\n",
       "      <td>0.743025</td>\n",
       "      <td>0.851950</td>\n",
       "      <td>0.053379</td>\n",
       "      <td>0.132240</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.044420</td>\n",
       "      <td>0.960228</td>\n",
       "      <td>0.029354</td>\n",
       "      <td>0.019296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760733</td>\n",
       "      <td>0.047803</td>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.230789</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>55.622177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11541</th>\n",
       "      <td>GSM1400060</td>\n",
       "      <td>0.748376</td>\n",
       "      <td>0.813206</td>\n",
       "      <td>0.037265</td>\n",
       "      <td>0.122670</td>\n",
       "      <td>0.066083</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.969954</td>\n",
       "      <td>0.033139</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>0.381791</td>\n",
       "      <td>0.045590</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>0.047357</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>56.481862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11542</th>\n",
       "      <td>GSM1400061</td>\n",
       "      <td>0.751430</td>\n",
       "      <td>0.762084</td>\n",
       "      <td>0.047129</td>\n",
       "      <td>0.135480</td>\n",
       "      <td>0.061990</td>\n",
       "      <td>0.056752</td>\n",
       "      <td>0.964156</td>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715017</td>\n",
       "      <td>0.068199</td>\n",
       "      <td>0.821700</td>\n",
       "      <td>0.069503</td>\n",
       "      <td>0.056313</td>\n",
       "      <td>0.357617</td>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.040809</td>\n",
       "      <td>0.034852</td>\n",
       "      <td>63.898700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11543 rows × 25980 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  cg00000292  cg00002426  cg00003994  cg00005847  cg00006414  \\\n",
       "0      GSM1500896    0.540079    0.564492    0.044907    0.699895    0.064083   \n",
       "1      GSM1500897    0.562377    0.563360    0.065536    0.639487    0.068047   \n",
       "2      GSM1500898    0.586262    0.556159    0.053013    0.592859    0.072489   \n",
       "3      GSM1500899    0.515197    0.582909    0.049645    0.764413    0.057259   \n",
       "4      GSM1500900    0.617524    0.604762    0.048714    0.436787    0.086947   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "11538  GSM1400057    0.813192    0.851833    0.063641    0.133013    0.083006   \n",
       "11539  GSM1400058    0.786084    0.817049    0.047396    0.126858    0.076139   \n",
       "11540  GSM1400059    0.743025    0.851950    0.053379    0.132240    0.068600   \n",
       "11541  GSM1400060    0.748376    0.813206    0.037265    0.122670    0.066083   \n",
       "11542  GSM1400061    0.751430    0.762084    0.047129    0.135480    0.061990   \n",
       "\n",
       "       cg00007981  cg00008493  cg00008713  cg00009407  ...  cg27653134  \\\n",
       "0        0.042312    0.856228    0.072350    0.044770  ...    0.710663   \n",
       "1        0.037802    0.828050    0.081527    0.056482  ...    0.686128   \n",
       "2        0.042100    0.842531    0.075749    0.051566  ...    0.719266   \n",
       "3        0.035079    0.867209    0.060494    0.050152  ...    0.657433   \n",
       "4        0.038958    0.858944    0.079839    0.046829  ...    0.698988   \n",
       "...           ...         ...         ...         ...  ...         ...   \n",
       "11538    0.044553    0.954777    0.036731    0.018631  ...    0.773726   \n",
       "11539    0.037249    0.964076    0.036162    0.018507  ...    0.774994   \n",
       "11540    0.044420    0.960228    0.029354    0.019296  ...    0.760733   \n",
       "11541    0.049799    0.969954    0.033139    0.016395  ...    0.784722   \n",
       "11542    0.056752    0.964156    0.032469    0.020460  ...    0.715017   \n",
       "\n",
       "       cg27654142  cg27655855  cg27655905  cg27657283  cg27661264  cg27662379  \\\n",
       "0        0.066649    0.837245    0.057018    0.049503    0.356949    0.069238   \n",
       "1        0.070768    0.794794    0.057936    0.047380    0.256544    0.064016   \n",
       "2        0.086908    0.827737    0.078091    0.053606    0.365556    0.054088   \n",
       "3        0.078306    0.788525    0.052291    0.053358    0.269563    0.064488   \n",
       "4        0.084030    0.799059    0.049743    0.036543    0.277516    0.060048   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "11538    0.096861    0.773328    0.057141    0.051934    0.231402    0.025213   \n",
       "11539    0.121388    0.776687    0.053314    0.068269    0.299261    0.022777   \n",
       "11540    0.047803    0.804805    0.056035    0.041141    0.230789    0.025726   \n",
       "11541    0.039983    0.381791    0.045590    0.029172    0.342303    0.022631   \n",
       "11542    0.068199    0.821700    0.069503    0.056313    0.357617    0.025499   \n",
       "\n",
       "       cg27662877  cg27665659        Age  \n",
       "0        0.040596    0.126728  71.000000  \n",
       "1        0.051418    0.122267  62.000000  \n",
       "2        0.049267    0.155096  77.000000  \n",
       "3        0.047505    0.138939  79.000000  \n",
       "4        0.054901    0.115813  70.000000  \n",
       "...           ...         ...        ...  \n",
       "11538    0.040151    0.035339  49.078713  \n",
       "11539    0.054795    0.036373  49.078713  \n",
       "11540    0.045395    0.034314  55.622177  \n",
       "11541    0.047357    0.030372  56.481862  \n",
       "11542    0.040809    0.034852  63.898700  \n",
       "\n",
       "[11543 rows x 25980 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6e0676-b809-4cf6-8396-c3ca2ccd6730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#行列名保存下来\n",
    "row_indices = df_raw['Unnamed: 0'].tolist()\n",
    "column_names = df_raw.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a60e5b-f224-49b8-93cf-0ae857943255",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00000292</th>\n",
       "      <th>cg00002426</th>\n",
       "      <th>cg00003994</th>\n",
       "      <th>cg00005847</th>\n",
       "      <th>cg00006414</th>\n",
       "      <th>cg00007981</th>\n",
       "      <th>cg00008493</th>\n",
       "      <th>cg00008713</th>\n",
       "      <th>cg00009407</th>\n",
       "      <th>cg00011459</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27653134</th>\n",
       "      <th>cg27654142</th>\n",
       "      <th>cg27655855</th>\n",
       "      <th>cg27655905</th>\n",
       "      <th>cg27657283</th>\n",
       "      <th>cg27661264</th>\n",
       "      <th>cg27662379</th>\n",
       "      <th>cg27662877</th>\n",
       "      <th>cg27665659</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM1500896</th>\n",
       "      <td>0.540079</td>\n",
       "      <td>0.564492</td>\n",
       "      <td>0.044907</td>\n",
       "      <td>0.699895</td>\n",
       "      <td>0.064083</td>\n",
       "      <td>0.042312</td>\n",
       "      <td>0.856228</td>\n",
       "      <td>0.072350</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>0.848418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710663</td>\n",
       "      <td>0.066649</td>\n",
       "      <td>0.837245</td>\n",
       "      <td>0.057018</td>\n",
       "      <td>0.049503</td>\n",
       "      <td>0.356949</td>\n",
       "      <td>0.069238</td>\n",
       "      <td>0.040596</td>\n",
       "      <td>0.126728</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1500897</th>\n",
       "      <td>0.562377</td>\n",
       "      <td>0.563360</td>\n",
       "      <td>0.065536</td>\n",
       "      <td>0.639487</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>0.037802</td>\n",
       "      <td>0.828050</td>\n",
       "      <td>0.081527</td>\n",
       "      <td>0.056482</td>\n",
       "      <td>0.827373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686128</td>\n",
       "      <td>0.070768</td>\n",
       "      <td>0.794794</td>\n",
       "      <td>0.057936</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.256544</td>\n",
       "      <td>0.064016</td>\n",
       "      <td>0.051418</td>\n",
       "      <td>0.122267</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1500898</th>\n",
       "      <td>0.586262</td>\n",
       "      <td>0.556159</td>\n",
       "      <td>0.053013</td>\n",
       "      <td>0.592859</td>\n",
       "      <td>0.072489</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.842531</td>\n",
       "      <td>0.075749</td>\n",
       "      <td>0.051566</td>\n",
       "      <td>0.814106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719266</td>\n",
       "      <td>0.086908</td>\n",
       "      <td>0.827737</td>\n",
       "      <td>0.078091</td>\n",
       "      <td>0.053606</td>\n",
       "      <td>0.365556</td>\n",
       "      <td>0.054088</td>\n",
       "      <td>0.049267</td>\n",
       "      <td>0.155096</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1500899</th>\n",
       "      <td>0.515197</td>\n",
       "      <td>0.582909</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.764413</td>\n",
       "      <td>0.057259</td>\n",
       "      <td>0.035079</td>\n",
       "      <td>0.867209</td>\n",
       "      <td>0.060494</td>\n",
       "      <td>0.050152</td>\n",
       "      <td>0.834977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657433</td>\n",
       "      <td>0.078306</td>\n",
       "      <td>0.788525</td>\n",
       "      <td>0.052291</td>\n",
       "      <td>0.053358</td>\n",
       "      <td>0.269563</td>\n",
       "      <td>0.064488</td>\n",
       "      <td>0.047505</td>\n",
       "      <td>0.138939</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1500900</th>\n",
       "      <td>0.617524</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.048714</td>\n",
       "      <td>0.436787</td>\n",
       "      <td>0.086947</td>\n",
       "      <td>0.038958</td>\n",
       "      <td>0.858944</td>\n",
       "      <td>0.079839</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>0.856805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698988</td>\n",
       "      <td>0.084030</td>\n",
       "      <td>0.799059</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.036543</td>\n",
       "      <td>0.277516</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.054901</td>\n",
       "      <td>0.115813</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1400057</th>\n",
       "      <td>0.813192</td>\n",
       "      <td>0.851833</td>\n",
       "      <td>0.063641</td>\n",
       "      <td>0.133013</td>\n",
       "      <td>0.083006</td>\n",
       "      <td>0.044553</td>\n",
       "      <td>0.954777</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>0.860106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773726</td>\n",
       "      <td>0.096861</td>\n",
       "      <td>0.773328</td>\n",
       "      <td>0.057141</td>\n",
       "      <td>0.051934</td>\n",
       "      <td>0.231402</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>0.040151</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>49.078713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1400058</th>\n",
       "      <td>0.786084</td>\n",
       "      <td>0.817049</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.076139</td>\n",
       "      <td>0.037249</td>\n",
       "      <td>0.964076</td>\n",
       "      <td>0.036162</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>0.865197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774994</td>\n",
       "      <td>0.121388</td>\n",
       "      <td>0.776687</td>\n",
       "      <td>0.053314</td>\n",
       "      <td>0.068269</td>\n",
       "      <td>0.299261</td>\n",
       "      <td>0.022777</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.036373</td>\n",
       "      <td>49.078713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1400059</th>\n",
       "      <td>0.743025</td>\n",
       "      <td>0.851950</td>\n",
       "      <td>0.053379</td>\n",
       "      <td>0.132240</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.044420</td>\n",
       "      <td>0.960228</td>\n",
       "      <td>0.029354</td>\n",
       "      <td>0.019296</td>\n",
       "      <td>0.917653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760733</td>\n",
       "      <td>0.047803</td>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.056035</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>0.230789</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>55.622177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1400060</th>\n",
       "      <td>0.748376</td>\n",
       "      <td>0.813206</td>\n",
       "      <td>0.037265</td>\n",
       "      <td>0.122670</td>\n",
       "      <td>0.066083</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.969954</td>\n",
       "      <td>0.033139</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>0.918028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.039983</td>\n",
       "      <td>0.381791</td>\n",
       "      <td>0.045590</td>\n",
       "      <td>0.029172</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>0.047357</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>56.481862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM1400061</th>\n",
       "      <td>0.751430</td>\n",
       "      <td>0.762084</td>\n",
       "      <td>0.047129</td>\n",
       "      <td>0.135480</td>\n",
       "      <td>0.061990</td>\n",
       "      <td>0.056752</td>\n",
       "      <td>0.964156</td>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>0.899011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715017</td>\n",
       "      <td>0.068199</td>\n",
       "      <td>0.821700</td>\n",
       "      <td>0.069503</td>\n",
       "      <td>0.056313</td>\n",
       "      <td>0.357617</td>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.040809</td>\n",
       "      <td>0.034852</td>\n",
       "      <td>63.898700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11543 rows × 25979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cg00000292  cg00002426  cg00003994  cg00005847  cg00006414  \\\n",
       "GSM1500896    0.540079    0.564492    0.044907    0.699895    0.064083   \n",
       "GSM1500897    0.562377    0.563360    0.065536    0.639487    0.068047   \n",
       "GSM1500898    0.586262    0.556159    0.053013    0.592859    0.072489   \n",
       "GSM1500899    0.515197    0.582909    0.049645    0.764413    0.057259   \n",
       "GSM1500900    0.617524    0.604762    0.048714    0.436787    0.086947   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "GSM1400057    0.813192    0.851833    0.063641    0.133013    0.083006   \n",
       "GSM1400058    0.786084    0.817049    0.047396    0.126858    0.076139   \n",
       "GSM1400059    0.743025    0.851950    0.053379    0.132240    0.068600   \n",
       "GSM1400060    0.748376    0.813206    0.037265    0.122670    0.066083   \n",
       "GSM1400061    0.751430    0.762084    0.047129    0.135480    0.061990   \n",
       "\n",
       "            cg00007981  cg00008493  cg00008713  cg00009407  cg00011459  ...  \\\n",
       "GSM1500896    0.042312    0.856228    0.072350    0.044770    0.848418  ...   \n",
       "GSM1500897    0.037802    0.828050    0.081527    0.056482    0.827373  ...   \n",
       "GSM1500898    0.042100    0.842531    0.075749    0.051566    0.814106  ...   \n",
       "GSM1500899    0.035079    0.867209    0.060494    0.050152    0.834977  ...   \n",
       "GSM1500900    0.038958    0.858944    0.079839    0.046829    0.856805  ...   \n",
       "...                ...         ...         ...         ...         ...  ...   \n",
       "GSM1400057    0.044553    0.954777    0.036731    0.018631    0.860106  ...   \n",
       "GSM1400058    0.037249    0.964076    0.036162    0.018507    0.865197  ...   \n",
       "GSM1400059    0.044420    0.960228    0.029354    0.019296    0.917653  ...   \n",
       "GSM1400060    0.049799    0.969954    0.033139    0.016395    0.918028  ...   \n",
       "GSM1400061    0.056752    0.964156    0.032469    0.020460    0.899011  ...   \n",
       "\n",
       "            cg27653134  cg27654142  cg27655855  cg27655905  cg27657283  \\\n",
       "GSM1500896    0.710663    0.066649    0.837245    0.057018    0.049503   \n",
       "GSM1500897    0.686128    0.070768    0.794794    0.057936    0.047380   \n",
       "GSM1500898    0.719266    0.086908    0.827737    0.078091    0.053606   \n",
       "GSM1500899    0.657433    0.078306    0.788525    0.052291    0.053358   \n",
       "GSM1500900    0.698988    0.084030    0.799059    0.049743    0.036543   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "GSM1400057    0.773726    0.096861    0.773328    0.057141    0.051934   \n",
       "GSM1400058    0.774994    0.121388    0.776687    0.053314    0.068269   \n",
       "GSM1400059    0.760733    0.047803    0.804805    0.056035    0.041141   \n",
       "GSM1400060    0.784722    0.039983    0.381791    0.045590    0.029172   \n",
       "GSM1400061    0.715017    0.068199    0.821700    0.069503    0.056313   \n",
       "\n",
       "            cg27661264  cg27662379  cg27662877  cg27665659        Age  \n",
       "GSM1500896    0.356949    0.069238    0.040596    0.126728  71.000000  \n",
       "GSM1500897    0.256544    0.064016    0.051418    0.122267  62.000000  \n",
       "GSM1500898    0.365556    0.054088    0.049267    0.155096  77.000000  \n",
       "GSM1500899    0.269563    0.064488    0.047505    0.138939  79.000000  \n",
       "GSM1500900    0.277516    0.060048    0.054901    0.115813  70.000000  \n",
       "...                ...         ...         ...         ...        ...  \n",
       "GSM1400057    0.231402    0.025213    0.040151    0.035339  49.078713  \n",
       "GSM1400058    0.299261    0.022777    0.054795    0.036373  49.078713  \n",
       "GSM1400059    0.230789    0.025726    0.045395    0.034314  55.622177  \n",
       "GSM1400060    0.342303    0.022631    0.047357    0.030372  56.481862  \n",
       "GSM1400061    0.357617    0.025499    0.040809    0.034852  63.898700  \n",
       "\n",
       "[11543 rows x 25979 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将第一列删除\n",
    "del df_raw['Unnamed: 0']\n",
    "#行名变为样本名\n",
    "df_raw.index = row_indices\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abaa76dc-ee1c-41ba-b68a-1dcc05a36de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11543, 25978, 1), (11543,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取特征列\n",
    "X = df_raw.iloc[:, :-1].values\n",
    "X = np.expand_dims(X.astype(float), axis=2)#增加一维轴\n",
    "# 提取标签列\n",
    "y = df_raw.iloc[:, -1].values\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9914151b-0cf2-4e84-9f36-17ddf48b28cd",
   "metadata": {},
   "source": [
    "### Divide the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af661571-e8ee-4fe8-b232-e4f032eccb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集，测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6df3a5-91c8-46dd-8a7b-f25811a360c5",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36d06245-ea46-45cc-ba13-233db4c95b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Block(input):\n",
    "    input_shape = Input(shape=(X_train.shape[1],1))\n",
    "    \n",
    "    #1st layer 如果卷积时，设置padding的属性值是 SAME ，则表示输出层尺寸 = 输入层尺寸\n",
    "    layer_1 = Conv1D(1,1,padding = 'same',activation='relu')(input)\n",
    "    dropout1 = Dropout(0.2)(layer_1)\n",
    "    #2nd layer\n",
    "    layer_2_1 = Conv1D(1, 1, padding='same', activation='relu')(input)\n",
    "    layer_2_2 = Conv1D(1, 8, padding='same', activation='relu')(layer_2_1)\n",
    "    dropout2 = Dropout(0.2)(layer_2_2)\n",
    "    #3rd layer\n",
    "    layer_3_1 = Conv1D(1, 1, padding='same', activation='relu')(input)\n",
    "    layer_3_2 = Conv1D(1, 16, padding='same', activation='relu')(layer_3_1)\n",
    "    layer_3_3 = Conv1D(1, 16, padding='same', activation='relu')(layer_3_2)\n",
    "    dropout3 = Dropout(0.2)(layer_3_3)\n",
    "    #4st layer\n",
    "    layer_4_1 = Conv1D(1, 1, padding='same', activation='relu')(input)\n",
    "    layer_4_2 = Conv1D(1, 32, padding='same', activation='relu')(layer_4_1)\n",
    "    layer_4_3 = Conv1D(1, 32, padding='same', activation='relu')(layer_4_2)\n",
    "    layer_4_4 = Conv1D(1, 32, padding='same', activation='relu')(layer_4_3)\n",
    "    dropout4 = Dropout(0.2)(layer_4_4)\n",
    "\n",
    "    output = keras.layers.concatenate([dropout1, dropout2, dropout3,dropout4], axis = 2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c960be19-9a99-42f5-8349-2f9f423373e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 25978, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_123 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_121 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_124 (Conv1D)            (None, 25978, 1)     129         ['conv1d_123[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_120 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_122 (Conv1D)            (None, 25978, 1)     9           ['conv1d_121[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_125 (Conv1D)            (None, 25978, 1)     129         ['conv1d_124[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 25978, 1)     0           ['conv1d_120[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 25978, 1)     0           ['conv1d_122[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 25978, 1)     0           ['conv1d_125[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 25978, 3)     0           ['dropout_43[0][0]',             \n",
      "                                                                  'dropout_44[0][0]',             \n",
      "                                                                  'dropout_45[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_117 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_135 (Conv1D)            (None, 25978, 1)     4           ['concatenate_23[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_115 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_118 (Conv1D)            (None, 25978, 1)     129         ['conv1d_117[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_133 (Conv1D)            (None, 25978, 1)     4           ['concatenate_23[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_136 (Conv1D)            (None, 25978, 1)     129         ['conv1d_135[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_114 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_116 (Conv1D)            (None, 25978, 1)     9           ['conv1d_115[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_119 (Conv1D)            (None, 25978, 1)     129         ['conv1d_118[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_132 (Conv1D)            (None, 25978, 1)     4           ['concatenate_23[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_134 (Conv1D)            (None, 25978, 1)     9           ['conv1d_133[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_137 (Conv1D)            (None, 25978, 1)     129         ['conv1d_136[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 25978, 1)     0           ['conv1d_114[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 25978, 1)     0           ['conv1d_116[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 25978, 1)     0           ['conv1d_119[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 25978, 1)     0           ['conv1d_132[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 25978, 1)     0           ['conv1d_134[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 25978, 1)     0           ['conv1d_137[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 25978, 3)     0           ['dropout_40[0][0]',             \n",
      "                                                                  'dropout_41[0][0]',             \n",
      "                                                                  'dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 25978, 3)     0           ['dropout_49[0][0]',             \n",
      "                                                                  'dropout_50[0][0]',             \n",
      "                                                                  'dropout_51[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_111 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_129 (Conv1D)            (None, 25978, 1)     4           ['concatenate_22[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_141 (Conv1D)            (None, 25978, 1)     4           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_109 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_112 (Conv1D)            (None, 25978, 1)     129         ['conv1d_111[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_127 (Conv1D)            (None, 25978, 1)     4           ['concatenate_22[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_130 (Conv1D)            (None, 25978, 1)     129         ['conv1d_129[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_139 (Conv1D)            (None, 25978, 1)     4           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_142 (Conv1D)            (None, 25978, 1)     129         ['conv1d_141[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_108 (Conv1D)            (None, 25978, 1)     2           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_110 (Conv1D)            (None, 25978, 1)     9           ['conv1d_109[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_113 (Conv1D)            (None, 25978, 1)     129         ['conv1d_112[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_126 (Conv1D)            (None, 25978, 1)     4           ['concatenate_22[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_128 (Conv1D)            (None, 25978, 1)     9           ['conv1d_127[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_131 (Conv1D)            (None, 25978, 1)     129         ['conv1d_130[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_138 (Conv1D)            (None, 25978, 1)     4           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_140 (Conv1D)            (None, 25978, 1)     9           ['conv1d_139[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_143 (Conv1D)            (None, 25978, 1)     129         ['conv1d_142[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 25978, 1)     0           ['conv1d_108[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 25978, 1)     0           ['conv1d_110[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 25978, 1)     0           ['conv1d_113[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 25978, 1)     0           ['conv1d_126[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 25978, 1)     0           ['conv1d_128[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 25978, 1)     0           ['conv1d_131[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 25978, 1)     0           ['conv1d_138[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 25978, 1)     0           ['conv1d_140[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 25978, 1)     0           ['conv1d_143[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 25978, 3)     0           ['dropout_37[0][0]',             \n",
      "                                                                  'dropout_38[0][0]',             \n",
      "                                                                  'dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 25978, 3)     0           ['dropout_46[0][0]',             \n",
      "                                                                  'dropout_47[0][0]',             \n",
      "                                                                  'dropout_48[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 25978, 3)     0           ['dropout_52[0][0]',             \n",
      "                                                                  'dropout_53[0][0]',             \n",
      "                                                                  'dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 25978, 9)     0           ['concatenate_21[0][0]',         \n",
      "                                                                  'concatenate_24[0][0]',         \n",
      "                                                                  'concatenate_26[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 233802)       0           ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           3740848     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 16)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            17          ['dropout_55[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,742,521\n",
      "Trainable params: 3,742,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#输入\n",
    "input_shape = Input(shape=(X_train.shape[1],1))\n",
    "#全连接层1\n",
    "fc1 = Dense(512, activation='relu')(input_shape)\n",
    "fc2 = Dense(25789, activation='linear')(fc1)\n",
    "#调用block，构成MSCNN模块\n",
    "#第一列\n",
    "block1 = Block(fc2)\n",
    "block2 = Block(fc2)\n",
    "block3 = Block(fc2)\n",
    "block4 = Block(fc2)\n",
    "#第二列\n",
    "block5 = Block(block2)\n",
    "block6 = Block(block3)\n",
    "block7 = Block(block4)\n",
    "#第三列\n",
    "block8 = Block(block6)\n",
    "block9 = Block(block7)\n",
    "#第四列\n",
    "block10 = Block(block9)\n",
    "#合并\n",
    "MSCNN = keras.layers.concatenate([block1, block5, block8，block10, axis = 2)\n",
    "\n",
    "flat_1 = Flatten()(MSCNN)\n",
    "output1 = Dense(16, activation='relu')(flat_1)\n",
    "dropout = Dropout(0.2)(output1)\n",
    "output = Dense(1, activation='linear')(dropout)\n",
    "\n",
    "model = Model([input_shape], output)\n",
    "model.summary()\n",
    "adam = keras.optimizers.adam_v2.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4192f-f65a-473e-afac-5fbe6b31cc0f",
   "metadata": {},
   "source": [
    "### batch_size过大或者其他原因可能会导致占用内存过大，因此训练模型前可以提前释放一下服务器上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "323648a8-a9df-4c13-9440-6536e5f8dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import set_session\n",
    "from keras.backend import clear_session\n",
    "from keras.backend import get_session\n",
    "import tensorflow as tf\n",
    "import gc\n",
    " \n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    " \n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    " \n",
    "    print(gc.collect()) # if it does something you should see a number as output\n",
    " \n",
    "    # use the same config as you used to create the session\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd03b0ca-a675-43a7-ab95-82f24e3cd83a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:42:09.456925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.457346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.457585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.457872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.458092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.458248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14622 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:07.0, compute capability: 7.0\n",
      "2023-10-10 21:42:09.637842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.638249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.638488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.638770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.638990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-10-10 21:42:09.639147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14622 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:07.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "reset_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "796f912a-0e14-4137-af3d-e4f2ace9590d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:42:18.352937: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 959523408 exceeds 10% of free system memory.\n",
      "2023-10-10 21:42:19.816293: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 959523408 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 21:42:28.116971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 182s 2s/step - loss: 901.4749 - mae: 24.9315 - val_loss: 673.5410 - val_mae: 22.1100\n",
      "Epoch 2/200\n",
      "73/73 [==============================] - 24s 322ms/step - loss: 708.0542 - mae: 22.3582 - val_loss: 598.1550 - val_mae: 20.7400\n",
      "Epoch 3/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 631.4023 - mae: 20.8729 - val_loss: 544.6166 - val_mae: 19.4451\n",
      "Epoch 4/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 581.0054 - mae: 19.8254 - val_loss: 483.0451 - val_mae: 18.2873\n",
      "Epoch 5/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 529.5095 - mae: 18.7594 - val_loss: 441.5721 - val_mae: 17.4928\n",
      "Epoch 6/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 495.4940 - mae: 18.0392 - val_loss: 398.6919 - val_mae: 16.5242\n",
      "Epoch 7/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 456.0855 - mae: 17.1770 - val_loss: 363.4181 - val_mae: 15.6558\n",
      "Epoch 8/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 418.3072 - mae: 16.3561 - val_loss: 333.2023 - val_mae: 15.0673\n",
      "Epoch 9/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 400.0171 - mae: 15.9728 - val_loss: 313.1384 - val_mae: 14.2331\n",
      "Epoch 10/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 368.9631 - mae: 15.1453 - val_loss: 282.1266 - val_mae: 13.5603\n",
      "Epoch 11/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 353.5718 - mae: 14.6977 - val_loss: 260.2453 - val_mae: 12.8525\n",
      "Epoch 12/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 329.8730 - mae: 14.0840 - val_loss: 242.1860 - val_mae: 12.3384\n",
      "Epoch 13/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 329.3759 - mae: 13.9565 - val_loss: 228.5061 - val_mae: 12.0261\n",
      "Epoch 14/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 303.2878 - mae: 13.3504 - val_loss: 238.1226 - val_mae: 11.7171\n",
      "Epoch 15/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 290.5697 - mae: 12.9834 - val_loss: 214.7805 - val_mae: 11.1441\n",
      "Epoch 16/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 275.7784 - mae: 12.5506 - val_loss: 199.2375 - val_mae: 10.7272\n",
      "Epoch 17/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 273.4388 - mae: 12.4081 - val_loss: 197.7020 - val_mae: 10.5666\n",
      "Epoch 18/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 263.8575 - mae: 12.1611 - val_loss: 186.8157 - val_mae: 10.2180\n",
      "Epoch 19/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 258.9251 - mae: 12.0583 - val_loss: 172.6528 - val_mae: 9.8653\n",
      "Epoch 20/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 254.2608 - mae: 11.9102 - val_loss: 173.2840 - val_mae: 9.7915\n",
      "Epoch 21/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 244.2601 - mae: 11.6008 - val_loss: 178.0262 - val_mae: 9.8183\n",
      "Epoch 22/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 246.1089 - mae: 11.6561 - val_loss: 172.0844 - val_mae: 9.5919\n",
      "Epoch 23/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 232.5415 - mae: 11.2951 - val_loss: 157.3047 - val_mae: 9.2315\n",
      "Epoch 24/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 233.0303 - mae: 11.2922 - val_loss: 168.4540 - val_mae: 9.3988\n",
      "Epoch 25/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 227.1820 - mae: 11.1081 - val_loss: 137.6832 - val_mae: 8.6386\n",
      "Epoch 26/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 231.9147 - mae: 11.1941 - val_loss: 174.9921 - val_mae: 9.6916\n",
      "Epoch 27/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 227.3610 - mae: 11.1499 - val_loss: 157.8217 - val_mae: 9.1320\n",
      "Epoch 28/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 220.7794 - mae: 10.9243 - val_loss: 129.0890 - val_mae: 8.2886\n",
      "Epoch 29/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 225.7810 - mae: 10.9858 - val_loss: 160.9301 - val_mae: 9.1965\n",
      "Epoch 30/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 218.1882 - mae: 10.7671 - val_loss: 153.3483 - val_mae: 9.0546\n",
      "Epoch 31/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 213.5275 - mae: 10.6086 - val_loss: 187.4775 - val_mae: 10.2966\n",
      "Epoch 32/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 217.4299 - mae: 10.7328 - val_loss: 127.9988 - val_mae: 8.1536\n",
      "Epoch 33/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 214.1734 - mae: 10.6045 - val_loss: 115.6020 - val_mae: 7.7317\n",
      "Epoch 34/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 203.3642 - mae: 10.4201 - val_loss: 139.4433 - val_mae: 8.4757\n",
      "Epoch 35/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 212.8053 - mae: 10.5614 - val_loss: 125.3057 - val_mae: 8.1284\n",
      "Epoch 36/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 204.0584 - mae: 10.3790 - val_loss: 212.0205 - val_mae: 11.1934\n",
      "Epoch 37/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 205.3668 - mae: 10.4644 - val_loss: 130.2093 - val_mae: 8.1017\n",
      "Epoch 38/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 202.6608 - mae: 10.3523 - val_loss: 166.3573 - val_mae: 9.4500\n",
      "Epoch 39/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 202.9135 - mae: 10.2414 - val_loss: 117.5660 - val_mae: 7.6811\n",
      "Epoch 40/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 200.7406 - mae: 10.1874 - val_loss: 156.2456 - val_mae: 9.0007\n",
      "Epoch 41/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 196.8921 - mae: 10.1831 - val_loss: 127.7313 - val_mae: 8.1101\n",
      "Epoch 42/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 189.5661 - mae: 9.8892 - val_loss: 162.4279 - val_mae: 9.3200\n",
      "Epoch 43/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 190.2958 - mae: 9.9146 - val_loss: 107.5780 - val_mae: 7.3513\n",
      "Epoch 44/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 193.0779 - mae: 10.0986 - val_loss: 105.1560 - val_mae: 7.2498\n",
      "Epoch 45/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 191.9337 - mae: 10.0035 - val_loss: 138.4133 - val_mae: 8.7071\n",
      "Epoch 46/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 190.4845 - mae: 9.9268 - val_loss: 143.6946 - val_mae: 8.7414\n",
      "Epoch 47/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 187.8992 - mae: 9.9030 - val_loss: 103.6492 - val_mae: 7.2200\n",
      "Epoch 48/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 187.5538 - mae: 9.8531 - val_loss: 122.8303 - val_mae: 7.9116\n",
      "Epoch 49/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 183.6529 - mae: 9.7387 - val_loss: 126.1049 - val_mae: 8.0448\n",
      "Epoch 50/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 190.7354 - mae: 9.8761 - val_loss: 88.8834 - val_mae: 6.6412\n",
      "Epoch 51/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 180.0743 - mae: 9.6631 - val_loss: 126.6996 - val_mae: 8.1242\n",
      "Epoch 52/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 182.3010 - mae: 9.7289 - val_loss: 178.4947 - val_mae: 10.2317\n",
      "Epoch 53/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 185.1709 - mae: 9.7219 - val_loss: 112.3795 - val_mae: 7.5858\n",
      "Epoch 54/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 177.0028 - mae: 9.5271 - val_loss: 127.0784 - val_mae: 8.0908\n",
      "Epoch 55/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 179.2930 - mae: 9.5827 - val_loss: 129.9700 - val_mae: 8.2592\n",
      "Epoch 56/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 184.0599 - mae: 9.6332 - val_loss: 145.4125 - val_mae: 8.8108\n",
      "Epoch 57/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 178.8349 - mae: 9.6132 - val_loss: 161.6396 - val_mae: 9.5453\n",
      "Epoch 58/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 176.6650 - mae: 9.5267 - val_loss: 151.5959 - val_mae: 9.1954\n",
      "Epoch 59/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 175.0804 - mae: 9.4013 - val_loss: 102.0566 - val_mae: 7.1103\n",
      "Epoch 60/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 178.2948 - mae: 9.4811 - val_loss: 116.1091 - val_mae: 7.6692\n",
      "Epoch 61/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 173.6440 - mae: 9.4168 - val_loss: 161.6950 - val_mae: 9.6958\n",
      "Epoch 62/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 171.2665 - mae: 9.3336 - val_loss: 118.2462 - val_mae: 7.9092\n",
      "Epoch 63/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 176.6433 - mae: 9.3885 - val_loss: 123.0875 - val_mae: 8.0040\n",
      "Epoch 64/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 171.4816 - mae: 9.2491 - val_loss: 86.2561 - val_mae: 6.5247\n",
      "Epoch 65/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 180.9190 - mae: 9.5778 - val_loss: 162.2921 - val_mae: 9.5916\n",
      "Epoch 66/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 173.2103 - mae: 9.3125 - val_loss: 144.8715 - val_mae: 8.9964\n",
      "Epoch 67/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 168.7184 - mae: 9.2405 - val_loss: 102.0776 - val_mae: 7.1185\n",
      "Epoch 68/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 167.5603 - mae: 9.2660 - val_loss: 96.4833 - val_mae: 6.9873\n",
      "Epoch 69/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 171.2487 - mae: 9.3171 - val_loss: 83.0242 - val_mae: 6.2361\n",
      "Epoch 70/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 172.9473 - mae: 9.3346 - val_loss: 154.5307 - val_mae: 9.4147\n",
      "Epoch 71/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 166.8878 - mae: 9.1981 - val_loss: 121.3069 - val_mae: 8.0251\n",
      "Epoch 72/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 169.4679 - mae: 9.2136 - val_loss: 107.2388 - val_mae: 7.4475\n",
      "Epoch 73/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 163.4916 - mae: 9.0423 - val_loss: 153.2267 - val_mae: 9.6293\n",
      "Epoch 74/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 170.4674 - mae: 9.2498 - val_loss: 103.2248 - val_mae: 7.2577\n",
      "Epoch 75/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 168.0764 - mae: 9.1200 - val_loss: 126.2221 - val_mae: 8.3351\n",
      "Epoch 76/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 167.3262 - mae: 9.1236 - val_loss: 105.1479 - val_mae: 7.2775\n",
      "Epoch 77/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 169.2303 - mae: 9.0744 - val_loss: 133.7570 - val_mae: 8.6952\n",
      "Epoch 78/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 162.3704 - mae: 8.9603 - val_loss: 118.5937 - val_mae: 8.0089\n",
      "Epoch 79/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 170.5489 - mae: 9.2167 - val_loss: 155.1617 - val_mae: 9.4832\n",
      "Epoch 80/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 160.0122 - mae: 8.9443 - val_loss: 89.3166 - val_mae: 6.4960\n",
      "Epoch 81/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 160.5658 - mae: 9.0088 - val_loss: 131.7590 - val_mae: 8.5458\n",
      "Epoch 82/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 166.3443 - mae: 9.1054 - val_loss: 108.6996 - val_mae: 7.4596\n",
      "Epoch 83/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 164.3053 - mae: 9.0463 - val_loss: 169.8345 - val_mae: 10.1987\n",
      "Epoch 84/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 166.4346 - mae: 9.0170 - val_loss: 100.9588 - val_mae: 7.2878\n",
      "Epoch 85/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 162.4613 - mae: 8.9931 - val_loss: 80.3314 - val_mae: 6.1418\n",
      "Epoch 86/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 156.6313 - mae: 8.8230 - val_loss: 140.0502 - val_mae: 8.9716\n",
      "Epoch 87/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 160.5444 - mae: 8.9905 - val_loss: 95.3801 - val_mae: 6.9732\n",
      "Epoch 88/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 161.0672 - mae: 8.9378 - val_loss: 125.1468 - val_mae: 8.3599\n",
      "Epoch 89/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 156.3316 - mae: 8.7446 - val_loss: 107.0375 - val_mae: 7.3485\n",
      "Epoch 90/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 158.5306 - mae: 8.8006 - val_loss: 120.3017 - val_mae: 8.0556\n",
      "Epoch 91/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 161.0495 - mae: 8.9247 - val_loss: 113.4941 - val_mae: 7.8559\n",
      "Epoch 92/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 160.8972 - mae: 8.9314 - val_loss: 92.3427 - val_mae: 6.8013\n",
      "Epoch 93/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 156.1435 - mae: 8.7486 - val_loss: 103.9722 - val_mae: 7.4199\n",
      "Epoch 94/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 150.5091 - mae: 8.6935 - val_loss: 169.4824 - val_mae: 10.1784\n",
      "Epoch 95/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 157.6294 - mae: 8.8015 - val_loss: 114.5976 - val_mae: 7.8066\n",
      "Epoch 96/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 160.9473 - mae: 8.9276 - val_loss: 100.7597 - val_mae: 7.2241\n",
      "Epoch 97/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 159.7956 - mae: 8.9643 - val_loss: 198.7107 - val_mae: 11.2881\n",
      "Epoch 98/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 157.9475 - mae: 8.8887 - val_loss: 216.9400 - val_mae: 11.8577\n",
      "Epoch 99/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 158.8923 - mae: 8.8099 - val_loss: 101.1297 - val_mae: 7.3019\n",
      "Epoch 100/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 157.6281 - mae: 8.8009 - val_loss: 159.8754 - val_mae: 9.9562\n",
      "Epoch 101/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 157.3995 - mae: 8.7552 - val_loss: 129.5063 - val_mae: 8.4659\n",
      "Epoch 102/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 153.9457 - mae: 8.7233 - val_loss: 97.9493 - val_mae: 7.1554\n",
      "Epoch 103/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 150.3143 - mae: 8.5787 - val_loss: 72.4621 - val_mae: 5.9294\n",
      "Epoch 104/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 156.9184 - mae: 8.7784 - val_loss: 147.2228 - val_mae: 9.4885\n",
      "Epoch 105/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 159.3994 - mae: 8.9069 - val_loss: 150.2780 - val_mae: 9.5925\n",
      "Epoch 106/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 150.5866 - mae: 8.6003 - val_loss: 95.5757 - val_mae: 7.2192\n",
      "Epoch 107/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 158.7004 - mae: 8.8453 - val_loss: 123.5664 - val_mae: 8.3881\n",
      "Epoch 108/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 151.8709 - mae: 8.6611 - val_loss: 126.3978 - val_mae: 8.5852\n",
      "Epoch 109/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 152.2796 - mae: 8.6246 - val_loss: 97.4536 - val_mae: 7.2277\n",
      "Epoch 110/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 156.3087 - mae: 8.7183 - val_loss: 103.3983 - val_mae: 7.4144\n",
      "Epoch 111/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 152.7535 - mae: 8.6947 - val_loss: 66.8643 - val_mae: 5.5865\n",
      "Epoch 112/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 150.0323 - mae: 8.5595 - val_loss: 93.1613 - val_mae: 7.0215\n",
      "Epoch 113/200\n",
      "73/73 [==============================] - 24s 323ms/step - loss: 147.4287 - mae: 8.5767 - val_loss: 117.0726 - val_mae: 8.2338\n",
      "Epoch 114/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 154.9956 - mae: 8.7067 - val_loss: 70.3241 - val_mae: 5.6402\n",
      "Epoch 115/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 146.2279 - mae: 8.4846 - val_loss: 82.2652 - val_mae: 6.3877\n",
      "Epoch 116/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 154.4812 - mae: 8.6977 - val_loss: 88.4655 - val_mae: 6.7285\n",
      "Epoch 117/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 150.8211 - mae: 8.4948 - val_loss: 95.8866 - val_mae: 7.1217\n",
      "Epoch 118/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 151.4632 - mae: 8.5663 - val_loss: 111.4038 - val_mae: 8.0002\n",
      "Epoch 119/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 145.4459 - mae: 8.4681 - val_loss: 78.0708 - val_mae: 6.1994\n",
      "Epoch 120/200\n",
      "73/73 [==============================] - 24s 323ms/step - loss: 147.3874 - mae: 8.5352 - val_loss: 102.9355 - val_mae: 7.3710\n",
      "Epoch 121/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 146.7658 - mae: 8.4257 - val_loss: 62.6036 - val_mae: 5.3643\n",
      "Epoch 122/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 150.0538 - mae: 8.5503 - val_loss: 78.7686 - val_mae: 6.1521\n",
      "Epoch 123/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 144.2124 - mae: 8.4033 - val_loss: 107.5327 - val_mae: 7.7575\n",
      "Epoch 124/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 150.8225 - mae: 8.5872 - val_loss: 116.4258 - val_mae: 8.2831\n",
      "Epoch 125/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 148.9917 - mae: 8.4688 - val_loss: 188.3839 - val_mae: 11.1312\n",
      "Epoch 126/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 159.7175 - mae: 8.8109 - val_loss: 109.7407 - val_mae: 7.8814\n",
      "Epoch 127/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 144.5936 - mae: 8.4068 - val_loss: 123.9549 - val_mae: 8.4221\n",
      "Epoch 128/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 143.8729 - mae: 8.3977 - val_loss: 104.7496 - val_mae: 7.5799\n",
      "Epoch 129/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 142.5738 - mae: 8.3254 - val_loss: 148.9234 - val_mae: 9.6408\n",
      "Epoch 130/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 149.2776 - mae: 8.5845 - val_loss: 94.2891 - val_mae: 7.1697\n",
      "Epoch 131/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 147.9145 - mae: 8.5892 - val_loss: 73.7066 - val_mae: 6.1036\n",
      "Epoch 132/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 141.4070 - mae: 8.3475 - val_loss: 113.0261 - val_mae: 8.0668\n",
      "Epoch 133/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 148.5855 - mae: 8.4757 - val_loss: 142.3989 - val_mae: 9.3507\n",
      "Epoch 134/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 143.1689 - mae: 8.3492 - val_loss: 99.9998 - val_mae: 7.3032\n",
      "Epoch 135/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 146.8416 - mae: 8.4772 - val_loss: 72.7377 - val_mae: 5.9023\n",
      "Epoch 136/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 147.9943 - mae: 8.4142 - val_loss: 83.7991 - val_mae: 6.4879\n",
      "Epoch 137/200\n",
      "73/73 [==============================] - 24s 322ms/step - loss: 143.9753 - mae: 8.3723 - val_loss: 117.2915 - val_mae: 8.2086\n",
      "Epoch 138/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 141.6951 - mae: 8.2931 - val_loss: 118.3030 - val_mae: 8.2429\n",
      "Epoch 139/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 150.7744 - mae: 8.5215 - val_loss: 114.5923 - val_mae: 8.2584\n",
      "Epoch 140/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 145.2533 - mae: 8.3689 - val_loss: 121.0423 - val_mae: 8.4507\n",
      "Epoch 141/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 143.6432 - mae: 8.3396 - val_loss: 110.5085 - val_mae: 7.9402\n",
      "Epoch 142/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 145.7995 - mae: 8.3961 - val_loss: 88.0687 - val_mae: 6.8636\n",
      "Epoch 143/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 149.2050 - mae: 8.4939 - val_loss: 81.0455 - val_mae: 6.4614\n",
      "Epoch 144/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 140.7515 - mae: 8.2808 - val_loss: 103.8008 - val_mae: 7.6740\n",
      "Epoch 145/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 141.6352 - mae: 8.2284 - val_loss: 131.3203 - val_mae: 8.8422\n",
      "Epoch 146/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 146.5010 - mae: 8.4114 - val_loss: 72.0499 - val_mae: 5.9970\n",
      "Epoch 147/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 148.0633 - mae: 8.5604 - val_loss: 95.2647 - val_mae: 7.2855\n",
      "Epoch 148/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 151.1253 - mae: 8.5333 - val_loss: 76.0418 - val_mae: 6.2791\n",
      "Epoch 149/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 148.2914 - mae: 8.4847 - val_loss: 139.6606 - val_mae: 9.3383\n",
      "Epoch 150/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 140.3965 - mae: 8.2435 - val_loss: 70.0512 - val_mae: 5.8313\n",
      "Epoch 151/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 144.4672 - mae: 8.3789 - val_loss: 100.2529 - val_mae: 7.6808\n",
      "Epoch 152/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 145.5892 - mae: 8.3935 - val_loss: 98.0486 - val_mae: 7.2369\n",
      "Epoch 153/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 144.1365 - mae: 8.3930 - val_loss: 95.9759 - val_mae: 7.2688\n",
      "Epoch 154/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 143.1805 - mae: 8.2890 - val_loss: 96.1020 - val_mae: 7.1530\n",
      "Epoch 155/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 145.7982 - mae: 8.3749 - val_loss: 98.9726 - val_mae: 7.4970\n",
      "Epoch 156/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 145.0053 - mae: 8.3817 - val_loss: 99.3227 - val_mae: 7.5686\n",
      "Epoch 157/200\n",
      "73/73 [==============================] - 24s 322ms/step - loss: 148.7041 - mae: 8.4811 - val_loss: 95.2349 - val_mae: 7.1548\n",
      "Epoch 158/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 143.4233 - mae: 8.3469 - val_loss: 105.5711 - val_mae: 7.9162\n",
      "Epoch 159/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 142.4992 - mae: 8.3257 - val_loss: 104.0947 - val_mae: 7.8317\n",
      "Epoch 160/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 140.0589 - mae: 8.2812 - val_loss: 66.9268 - val_mae: 5.7105\n",
      "Epoch 161/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 143.6410 - mae: 8.2773 - val_loss: 75.8689 - val_mae: 6.3344\n",
      "Epoch 162/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 147.0975 - mae: 8.4191 - val_loss: 88.6278 - val_mae: 6.8031\n",
      "Epoch 163/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 143.5201 - mae: 8.2774 - val_loss: 87.0827 - val_mae: 6.8659\n",
      "Epoch 164/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 145.7321 - mae: 8.3640 - val_loss: 111.1974 - val_mae: 8.0844\n",
      "Epoch 165/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 138.6125 - mae: 8.1296 - val_loss: 64.4833 - val_mae: 5.5716\n",
      "Epoch 166/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 143.0317 - mae: 8.3949 - val_loss: 111.7340 - val_mae: 8.1208\n",
      "Epoch 167/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 146.0314 - mae: 8.3944 - val_loss: 63.8513 - val_mae: 5.5085\n",
      "Epoch 168/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 145.1951 - mae: 8.4802 - val_loss: 132.3251 - val_mae: 9.0139\n",
      "Epoch 169/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 141.6125 - mae: 8.2747 - val_loss: 62.3244 - val_mae: 5.3976\n",
      "Epoch 170/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 145.6459 - mae: 8.3795 - val_loss: 114.3112 - val_mae: 8.2708\n",
      "Epoch 171/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 137.4691 - mae: 8.1331 - val_loss: 126.8558 - val_mae: 8.9393\n",
      "Epoch 172/200\n",
      "73/73 [==============================] - 23s 322ms/step - loss: 144.1975 - mae: 8.3624 - val_loss: 68.4666 - val_mae: 5.7723\n",
      "Epoch 173/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 146.7757 - mae: 8.3437 - val_loss: 119.2885 - val_mae: 8.5597\n",
      "Epoch 174/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 140.3734 - mae: 8.2095 - val_loss: 87.0144 - val_mae: 6.9425\n",
      "Epoch 175/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 141.6106 - mae: 8.2251 - val_loss: 66.0037 - val_mae: 5.6184\n",
      "Epoch 176/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 144.3332 - mae: 8.2875 - val_loss: 89.5153 - val_mae: 6.9916\n",
      "Epoch 177/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 141.5450 - mae: 8.2001 - val_loss: 108.5228 - val_mae: 8.1106\n",
      "Epoch 178/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 142.2827 - mae: 8.2493 - val_loss: 132.6593 - val_mae: 9.0732\n",
      "Epoch 179/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 140.0918 - mae: 8.2000 - val_loss: 111.5601 - val_mae: 8.1013\n",
      "Epoch 180/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 140.7971 - mae: 8.2767 - val_loss: 70.8205 - val_mae: 5.9711\n",
      "Epoch 181/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 142.0449 - mae: 8.2803 - val_loss: 108.4134 - val_mae: 7.9330\n",
      "Epoch 182/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 142.3887 - mae: 8.2979 - val_loss: 140.6681 - val_mae: 9.3603\n",
      "Epoch 183/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 137.0861 - mae: 8.1669 - val_loss: 113.8560 - val_mae: 8.4087\n",
      "Epoch 184/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 142.0021 - mae: 8.2585 - val_loss: 135.9334 - val_mae: 9.2135\n",
      "Epoch 185/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 134.9764 - mae: 8.0922 - val_loss: 85.7279 - val_mae: 6.7239\n",
      "Epoch 186/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 145.2688 - mae: 8.3626 - val_loss: 149.8784 - val_mae: 9.9511\n",
      "Epoch 187/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 139.6015 - mae: 8.2137 - val_loss: 68.9248 - val_mae: 5.9768\n",
      "Epoch 188/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 138.6059 - mae: 8.2006 - val_loss: 92.0105 - val_mae: 7.1998\n",
      "Epoch 189/200\n",
      "73/73 [==============================] - 24s 322ms/step - loss: 137.1356 - mae: 8.1283 - val_loss: 55.4930 - val_mae: 5.0827\n",
      "Epoch 190/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 141.5731 - mae: 8.2909 - val_loss: 87.3395 - val_mae: 6.8263\n",
      "Epoch 191/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 133.5619 - mae: 8.0647 - val_loss: 93.4627 - val_mae: 7.3363\n",
      "Epoch 192/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 138.2677 - mae: 8.1986 - val_loss: 92.9585 - val_mae: 7.0564\n",
      "Epoch 193/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 142.0954 - mae: 8.2327 - val_loss: 109.5900 - val_mae: 8.1194\n",
      "Epoch 194/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 141.1234 - mae: 8.2751 - val_loss: 104.8998 - val_mae: 7.7413\n",
      "Epoch 195/200\n",
      "73/73 [==============================] - 24s 323ms/step - loss: 140.3728 - mae: 8.2101 - val_loss: 95.8684 - val_mae: 7.4766\n",
      "Epoch 196/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 136.5603 - mae: 8.0548 - val_loss: 85.3402 - val_mae: 6.9040\n",
      "Epoch 197/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 138.0352 - mae: 8.0785 - val_loss: 76.2857 - val_mae: 6.3381\n",
      "Epoch 198/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 141.1404 - mae: 8.2712 - val_loss: 149.8626 - val_mae: 9.9796\n",
      "Epoch 199/200\n",
      "73/73 [==============================] - 23s 320ms/step - loss: 135.7952 - mae: 8.1027 - val_loss: 70.9233 - val_mae: 6.0211\n",
      "Epoch 200/200\n",
      "73/73 [==============================] - 23s 321ms/step - loss: 139.3706 - mae: 8.2154 - val_loss: 132.2299 - val_mae: 9.1331\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "history = model.fit(X_train.astype(np.float32),Y_train.astype(np.float32), validation_data=(X_test.astype(np.float32), Y_test.astype(np.float32)),epochs=200, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14920c5c-f641-489b-91ed-afb148fba9ff",
   "metadata": {},
   "source": [
    "### Loss函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90f5395f-6040-4081-adc1-f4ed4ace905d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('LOSS')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64eccc52-8ab9-4582-9d11-82c5ec5730e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "# 保存训练好的model为hdf5文件\n",
    "model.save('../model/save_model/model.h5')  \n",
    "# 重新加载模型\n",
    "# model = load_model('../model/save_model/model_selu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbce378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取模型权重\n",
    "weights = model.get_weights() \n",
    "# 给模型权重赋值，注意列表中的数组必须与 get_weights() 返回的权重具有相同的尺寸。\n",
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ab1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# train\n",
    "predicted = model.predict(X_train)\n",
    "y_pred = []\n",
    "for i in predicted:\n",
    "    y_pred.append(i[0])\n",
    "y_pred = np.array(y_pred)\n",
    "sns.scatterplot(Y_train, y_pred,color='black', s=3)\n",
    "plt.legend([\"Pred Age\",\"y = x\"])\n",
    "plt.xlabel('True Age')\n",
    "plt.ylabel('Predicted Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d82f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# test\n",
    "predicted = model.predict(X_test)\n",
    "y_pred = []\n",
    "for i in predicted:\n",
    "    y_pred.append(i[0])\n",
    "y_pred = np.array(y_pred)\n",
    "sns.scatterplot(Y_test, y_pred,color='black', s=3)\n",
    "plt.legend([\"Pred Age\",\"y = x\"])\n",
    "plt.xlabel('True Age')\n",
    "plt.ylabel('Predicted Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics\n",
    "from sklearn import metrics\n",
    "from scipy.stats import pearsonr# R square way2\n",
    "mad = round((np.median(np.abs(np.array(y_pred)-Y_test))),2)\n",
    "mse = round((np.mean((np.array(y_pred)-Y_test) ** 2)),2)\n",
    "rmse = round((np.sqrt(mse)),2)\n",
    "pearsonR = round((pearsonr(Y_test, y_pred).statistic), 2)\n",
    "pearsonR,mad,mse,rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
